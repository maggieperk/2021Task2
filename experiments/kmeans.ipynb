{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "threaded-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "historical-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file and generate list of sentences\n",
    "def read_file_to_list_of_senteces(filename):\n",
    "    sentences = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # Lower case all the words\n",
    "            #print(line.split())\n",
    "            sentence = [w.lower() for w in line.split()]\n",
    "            #print(sentence)\n",
    "            sentences.append(sentence)\n",
    "    print(\"Total sentences read: \" + str(len(sentences)))\n",
    "    return sentences\n",
    "\n",
    "#filename = \"../data/dev_langs/Swedish.bible.txt\"\n",
    "#sentences = read_file_to_list_of_senteces(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eastern-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate word embeddings\n",
    "def generate_word_embeddings(sentences):\n",
    "    w2v = Word2Vec(sentences, min_count=1, size = 5)\n",
    "    return w2v\n",
    "\n",
    "#w2v = generate_word_embeddings(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "damaged-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words = list(w2v.wv.vocab)\n",
    "#words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "british-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = w2v[w2v.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "equivalent-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n= len(words)\n",
    "#n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "chubby-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clustering(n_clusters, word_embeddings):\n",
    "    kmeans_clustering = KMeans(n_clusters=n_clusters, random_state=0).fit(word_embeddings)\n",
    "    return kmeans_clustering\n",
    "\n",
    "#kmeans_clustering = generate_clustering(200, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cleared-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#centers = kmeans_clustering.cluster_centers_\n",
    "#centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "therapeutic-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_center_dict(center_indices, w2v_model):\n",
    "    cluster_center_dicts= dict()\n",
    "\n",
    "    for c in center_indices:    \n",
    "        word_rep = w2v_model.most_similar([c], [], topn=1)[0][0]\n",
    "        tuple_c = tuple(c)\n",
    "        cluster_center_dicts[tuple_c] = word_rep\n",
    "    return cluster_center_dicts\n",
    "    \n",
    "#cluster_center_dicts = create_cluster_center_dict(centers, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "focused-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paradigm_dict(kmeans_clustering, centers_dict, X):\n",
    "    print(len(centers_dict))\n",
    "    print(len(X))\n",
    "    \n",
    "    paradigm_dict = {k:[] for k in centers_dict.values()}\n",
    "    \n",
    "    print(\"Running predict on all training values\")\n",
    "    y_hats = kmeans_clustering.predict(X)\n",
    "    print(\"Prediction complete\")\n",
    "    for x, y in zip(X, y_hats):\n",
    "        center_embedding = centers[y]\n",
    "        cluster_key = centers_dict[tuple(center_embedding)]\n",
    "        \n",
    "        x_word = w2v.most_similar([x], [], topn=1)[0][0]\n",
    "        paradigm_dict[cluster_key].append(x_word)\n",
    "    print(\"Finished creating paradigm dict\")\n",
    "    return paradigm_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "popular-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result_to_file(paradigm_dict, output_file):\n",
    "    f = open(output_file, 'w')\n",
    "    l_count = 0\n",
    "    print(paradigm_dict.keys())\n",
    "    for lemma in paradigm_dict.keys():\n",
    "        f.write(lemma)\n",
    "        f.write(\"\\n\")\n",
    "        surface_forms = paradigm_dict[lemma]\n",
    "        for sf in surface_forms:\n",
    "            f.write(sf)\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        l_count +=1\n",
    "    print(str(l_count) + \"Lemmas written to file \" + output_file)\n",
    "    f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-concern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "excellent-taste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "24207\n",
      "Running predict on all training values\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilovepenguinsalot/anaconda3/envs/task2new/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating paradigm dict\n",
      "dict_keys(['lågorna', 'kommer', 'svår', 'bergfästena', 'hedmarken', 'måste', 'oväntat', 'föresätta', 'tapenes', 'nu', 'eder', 'verkställa', 'gingo', 'uppenbarare', 'parningstiden', 'ditt', 'tillräknas', 'appfia', 'fyra', 'gott', 'skevas', 'basuner', 'törstiga', 'bestå', 'avkomlingar', 'utmark', 'högtidligt', '“', 'prästen', 'dessa', 'for', 'betel', 'vattenbäckar', 'herrens', 'oförtänkt', 'granatäpplen', 'härjar', 'morgonen', 'o', 'edra', 'överträdelsers', 'alnar', 'allsmäktige', 'hade', 'glupskhet', 'hermons', 'fram', 'förhasta', 'röja', 'övertäckte', 'oroligheterna', 'måtta', 'jordans', 'vem', 'skriftlärdes', 'bevise', 'främlingar', 'kungöra', 'runtomkring', 'tjugusjunde', 'draga', 'hundra', 'än', 'strutsarna', 'bot', 'kom', 'sängs', 'intalar', 'blygd', 'herre', 'missunnsamhet', 'tempelinvigningens', 'glädjas', '-', 'son', 'äta', 'skröpligheter', 'bortfrätas', 'höjder', 'har', 'gjort', 'hosaja', 'styggelse*.', 'juda', 'diamantgriffel', 'leva', 'tillsammans', 'araméerna', 'ägande', 'tidsålders', 'ansikte', 'ett', 'medlidande', 'sade', 'lättare', 'revor', 'låt', 'hugnad', 'risataim', 'rasar', 'vill', 'min', 'utseendet', 'benob', 'putiels', 'höken', 'skedde', 'säg', 'vad', 'sina', 'ihjälslagne', 'trogne', 'kinneret', 'isai', 'mer', 'offer', 'mose', 'födde', 'rohaga', 'på', 'stammars', 'laglydnad', 'assir', 'sidoniskor', 'vara', 'eldkol', 'dina', '—till', 'detta', 'lovprisar', 'noomi', 'likasom', 'skola', 'vår', 'avföll', 'frodigaste', 'gömmer', 'tjugufem', 'tiggde', 'bileam', 'strimmiga', '?', 'söner', 'utstått', 'djur', 'sin', 'våra', 'höjt', 'hundrafalt', 'semajas', 'fader', 'förflyttade', 'fästen', 'hängdes', 'vitmening', 'beskärda', 'blivit', 'flytta', 'låta', 'vatten', 'var', 'ej', 'lag', 'skändligheters', 'uppväger', 'svärdotters', 'därefter', 'myckenhetens', 'laodiceas', 'förvissa', 'hassub', 'arbeten', 'kloke', 'sefatja', 'förvirra', 'väderstreck', 'avskräde', 'aspata', 'sköta', 'misshag', 'komma', 'kamon', 'jag', 'munväder', 'vid', 'avhänder', 'genomgå', 'stefanas', 'diblataima', 'andres', 'tvår', 'tabernaklets', 'seeb', 'något', 'omkommit', 'svarade', 'gick', 'östanvind'])\n",
      "198Lemmas written to file ../output_files/swedish_cluster_out.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_name = \"../output_files/swedish_cluster_out.txt\"\n",
    "paradigm_dict = create_paradigm_dict(kmeans_clustering, cluster_center_dicts, X)\n",
    "write_result_to_file(paradigm_dict, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "republican-frame",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-de378bd589d8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-de378bd589d8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from 2021Task2.evaluate.eval import eval\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from 2021Task2.evaluate.eval import eval\n",
    "swedish_gold = \"../data/dev_langs/Swedish.dev.gold\"\n",
    "eval(output_file_name, swedish_gold)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "three-company",
   "metadata": {},
   "source": [
    "# Result from eval with 200 centers:\n",
    " python eval.py --reference \"../data/dev_langs/Swedish.dev.gold\" --prediction \"../output_files/swedish_cluster_out.txt\"\n",
    "precision: 0.05080763582966226\n",
    "recall: 0.04810901001112347\n",
    "f1: 0.049421511212683907\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "criminal-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_kmeans_clustering_for_file(filename, num_clusters, output_file):\n",
    "    sentences = read_file_to_list_of_senteces(filename)\n",
    "    w2v = generate_word_embeddings(sentences)\n",
    "\n",
    "    # Create list of word embeddings for all words in the vocab to fit the model\n",
    "    X = w2v[w2v.wv.vocab]\n",
    "\n",
    "    # Create a kmeans clustering\n",
    "    kmeans_clustering = generate_clustering(num_clusters, X)\n",
    "    centers = kmeans_clustering.cluster_centers_\n",
    "    cluster_center_dicts = create_cluster_center_dict(centers, w2v)\n",
    "    \n",
    "    # Generate paradigm dict and write to file\n",
    "    paradigm_dict = create_paradigm_dict(kmeans_clustering, cluster_center_dicts, X)\n",
    "    write_result_to_file(paradigm_dict, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "virgin-rabbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 2000 clusters\n",
      "Total sentences read: 43904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilovepenguinsalot/anaconda3/envs/task2new/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cluster_centers_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-7b5969716223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running for 2000 clusters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mexecute_kmeans_clustering_for_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswedish_2000_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mswedish_4000_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../output_files/Swedish_kmeans_cluster_4000.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-83eca3b99b72>\u001b[0m in \u001b[0;36mexecute_kmeans_clustering_for_file\u001b[0;34m(filename, num_clusters, output_file)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Create a kmeans clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mkmeans_clustering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans_clustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mcluster_center_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cluster_center_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cluster_centers_'"
     ]
    }
   ],
   "source": [
    "# Run KMeans on Swedish\n",
    "filename = \"../data/dev_langs/Swedish.bible.txt\"\n",
    "swedish_2000_output = \"../output_files/Swedish_kmeans_cluster_2000.txt\"\n",
    "\n",
    "print(\"Running for 2000 clusters\")\n",
    "execute_kmeans_clustering_for_file(filename, 2000, swedish_2000_output)\n",
    "\n",
    "swedish_4000_output = \"../output_files/Swedish_kmeans_cluster_4000.txt\"\n",
    "print(\"Running for 4000 clusters\")\n",
    "execute_kmeans_clustering_for_file(filename, 4000, swedish_4000_output)\n",
    "\n",
    "# Run Kmeans on Russian\n",
    "print(\"Running for Russian\")\n",
    "russian_filename = \"../data/dev_langs/Russian.bible.txt\"\n",
    "\n",
    "print(\"Running for 200 clusters\")\n",
    "russian_200_output = \"../output_files/Russian_kmeans_cluster_200.txt\"\n",
    "execute_kmeans_clustering_for_file(russian_filename, 200, russian_200_output)\n",
    "\n",
    "print(\"Running for 2000 clusters\")\n",
    "russian_2000_output = \"../output_files/Russian_kmeans_cluster_2000.txt\"\n",
    "execute_kmeans_clustering_for_file(russian_filename, 2000, russian_2000_output)\n",
    "\n",
    "print(\"Running for 4000 clusters\")\n",
    "russian_4000_output = \"../output_files/Russian_kmeans_cluster_4000.txt\"\n",
    "execute_kmeans_clustering_for_file(russian_filename, 4000, russian_4000_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-madness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task2new",
   "language": "python",
   "name": "task2new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
